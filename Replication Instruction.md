
# LBUNet with AttentionSkipFusion

## ğŸ“– Overview
This repository contains the implementation of the baseline LBUNet and a modified version with AttentionSkipFusion (ASF) for medical image segmentation.

The baseline LBUNet leverages boundary-aware supervision and multiple auxiliary outputs for high segmentation accuracy. The modified model introduces AttentionSkipFusion for learnable skip connections while simplifying the decoder and removing auxiliary branches for faster inference.

---

## ğŸ” Replication Instructions

Follow the steps below to train and evaluate both the baseline and modified LBUNet models:

### ğŸ“ Step 1: Prepare Dataset on Google Drive

Create a directory in your **Google Drive** (e.g., `ISIC_2018_Dataset/`) and place the dataset inside it with the following structure:

```
ISIC_2018_Dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ points_boundary2/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ masks/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ masks/
```

---

### ğŸ› ï¸ Step 2: Update `dataset.py` with Dataset Directory

The default dataset path is hardcoded as:
```python
/content/drive/MyDrive/KaggleDatasets/ISIC_Datasets/ISIC_2018_Dataset/
```
Modify this in `dataset.py` or pass a `path_Data` argument in the config if your dataset path differs.

---

### ğŸ§  Step 3: Modify the Model Architecture

Implement your model changes (e.g., replacing merge modules with `AttentionSkipFusion`, changing supervision structure) in `lbunet.py`. Ensure the `forward()` method and output structure reflect these changes.

---

### ğŸ”§ Step 4: Adapt Training and Utility Scripts

In `utils.py`:
- Update the loss function if the model output structure is changed.
- Use `GT_BceDiceLoss` or `BceDiceLoss` as needed.

In `engine.py`:
- Ensure `train_one_epoch()` and `val_one_epoch()` match your modelâ€™s output format.

In `train.py`:
- Ensure the correct network is selected and model config is defined in `setting_config()`.

---

### ğŸ”— Step 5: Mount Google Drive in Google Colab

In your Colab notebook:
```python
from google.colab import drive
drive.mount('/content/drive')
```

---

### ğŸ“‚ Step 6: Set Working Directory and Adjust Paths

In `train.py`, the root directory is defined as:
```python
os.chdir('/content/drive/MyDrive/LBUNet Cancer')
```
Change this to your actual path if needed.

---

### ğŸ“¦ Step 7: Install Required Dependencies

Install dependencies in Colab:
```bash
!pip install tensorboardX timm scikit-learn pillow
```

---

### ğŸš€ Step 8: Run the Training Script

Start training:
```bash
!python train.py
```
The script handles training, validation, saving the best model, and final testing.

---

## ğŸ“œ License

This project is for research and academic use only.

## âœï¸ Acknowledgment

This work uses OpenAIâ€™s ChatGPT to assist in formalizing, summarizing, and organizing parts of the code and documentation.

